{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99965a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3850e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer \n",
    "from sklearn.impute import KNNImputer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e68619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4749, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/dc2yd0kn325bph09grgy33lr0000gn/T/ipykernel_97854/852193672.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nonmiss[cont_col] = (df_nonmiss[cont_col] - df_nonmiss[cont_col].mean()) / df_nonmiss[cont_col].std()\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_clean.csv', sep=',', encoding='latin-1')\n",
    "df = df.drop(columns=['PAQ706'])\n",
    "df = df.drop(columns = ['CDQ001', 'CDQ010', 'DIQ070', 'DBD100', 'highLDL'])\n",
    "\n",
    "#variable choice to create dataset for missignness simulation\n",
    "df_nonmiss = df[['SEQN','RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'RIDRETH3',\n",
    "                 'DMDCITZN', 'DMDEDUC2', 'BMXLEG', 'BPXPULS',\n",
    "                 'DIQ010', 'DIQ050', 'HIQ011', 'PAQ635', \n",
    "                 'PAQ650', 'PAQ665','PAD680', 'PAQ710', 'DR1TKCAL']]\n",
    "\n",
    "cont_cols = ['RIDAGEYR', 'BMXLEG', 'DR1TKCAL', 'PAD680']\n",
    "# Normalize continuous columns to standard Normal \n",
    "for cont_col in cont_cols: \n",
    "    df_nonmiss[cont_col] = (df_nonmiss[cont_col] - df_nonmiss[cont_col].mean()) / df_nonmiss[cont_col].std() \n",
    "\n",
    "\n",
    "np_nonmiss = df_nonmiss.to_numpy(copy=True, na_value=np.nan) # Convert dataframe to numpy array \n",
    "np_nonmiss = np_nonmiss[~np.isnan(np_nonmiss).any(axis=1), :] # delete rows with any missing values\n",
    "\n",
    "seqn = np_nonmiss[:, 0] #record seqn for rows in df_nonmiss\n",
    "np_nonmiss = np_nonmiss[:, 1:18] #remove seqn\n",
    "print(np.shape(np_nonmiss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b32577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion missing\n",
    "p = 0.1 \n",
    "\n",
    "#MCAR\n",
    "MCAR_data = np.copy(np_nonmiss) #init data\n",
    "MCAR_missing_indices = np.random.choice( # randomly select values from length ie flat array \n",
    "    len(np_nonmiss.flatten()), \n",
    "    size=int(len(np_nonmiss.flatten())*p)) \n",
    "\n",
    "MCAR_data.flat[MCAR_missing_indices] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adcfb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNAR_data = np.copy(np_nonmiss) #init data\n",
    "\n",
    "#find bmi values\n",
    "bmi = df.loc[df['SEQN'].isin(seqn)]['bmi'] #limit to subset in seqn, select col bmi\n",
    "bmi = bmi.to_numpy(copy=True, na_value=np.nan)\n",
    "\n",
    "#high bmi\n",
    "hibmi = (bmi > 25) #def of obesity\n",
    "#health bmi\n",
    "hebmi = (bmi < 25)\n",
    "\n",
    "#determine indicies with hi or low bmi values\n",
    "hibmi_ind = np.where(hibmi)[0]\n",
    "hebmi_ind = np.where(hebmi)[0]\n",
    "\n",
    "#randomly select indices for missing values\n",
    "MNAR_missing_diet_ind = np.random.choice(len(hibmi_ind),\n",
    "                                        size = round(len(hibmi_ind)*2*p/3)) #oversample hi bmi\n",
    "np.append(MNAR_missing_diet_ind, \n",
    "          np.random.choice(len(hebmi_ind),\n",
    "                           size = round(len(hebmi_ind)*p/3))) \n",
    "\n",
    "#remove those values from dataset\n",
    "for i in MNAR_missing_diet_ind: \n",
    "    MNAR_data[i, 16] = np.nan #16 col is DR1TKCAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78abeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAR\n",
    "\n",
    "# When data are MAR, the fact that the data are missing is systematically related to the observed\n",
    "# but not the unobserved data, eg. related to age \n",
    "\n",
    "MAR_data = np.copy(np_nonmiss) #init data\n",
    "\n",
    "#determine indicies with PAQ values\n",
    "PAQ1_ind = np.where(np_nonmiss[:, 12] == 1) #12 col is PAQ650\n",
    "PAQ2_ind = np.where(np_nonmiss[:, 12] == 2)\n",
    "\n",
    "#randomly select indices for missing values\n",
    "MAR_missing_diet_ind = np.random.choice(len(PAQ1_ind[0]),\n",
    "                                        size = round(len(PAQ1_ind[0])*p/3))\n",
    "np.append(MAR_missing_diet_ind, \n",
    "          np.random.choice(len(PAQ2_ind[0]),\n",
    "                           size = round(len(PAQ2_ind[0])*2*p/3))) #more PAQ=2 are missing\n",
    "\n",
    "#remove those values from dataset\n",
    "for i in MAR_missing_diet_ind: \n",
    "    MAR_data[i, 16] = np.nan #16 col is DR1TKCAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71b014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data, missing_indices, method): \n",
    "    if method in ['mean', 'most_frequent', 'median']: \n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=method)\n",
    "        imputed_data = imp.fit_transform(data)\n",
    "        \n",
    "    if method == \"multivariate_feature_imputation\": \n",
    "        imp = IterativeImputer(max_iter=5, random_state=0) \n",
    "        imputed_data = imp.fit_transform(data) \n",
    "\n",
    "    if method == \"knn\": \n",
    "        imputer = KNNImputer(n_neighbors=2, weights=\"uniform\") \n",
    "        imputed_data = imputer.fit_transform(data)\n",
    "    \n",
    "    # print(imputed_data[:3,:3])         \n",
    "    print(\"MSE = \", mean_squared_error(\n",
    "        np_nonmiss.flat[missing_indices], \n",
    "        imputed_data.flat[missing_indices])) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da112c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"MCAR_data\":[MCAR_data, MCAR_missing_indices], \n",
    "    \"MAR_data\":[MAR_data, MAR_missing_diet_ind], \n",
    "    \"MNAR_data\":[MNAR_data, MNAR_missing_diet_ind], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb035d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  MCAR_data \t method: mean\n",
      "MSE =  0.8143861420942045\n",
      "\n",
      "Data:  MCAR_data \t method: median\n",
      "MSE =  0.9021684450674861\n",
      "\n",
      "Data:  MCAR_data \t method: most_frequent\n",
      "MSE =  1.0989800205788496\n",
      "\n",
      "Data:  MCAR_data \t method: multivariate_feature_imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikunjgupta/work/virtualenvs/mtds/lib/python3.8/site-packages/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.5418165122022942\n",
      "\n",
      "Data:  MCAR_data \t method: knn\n",
      "MSE =  0.8495703776718395\n",
      "\n",
      "=============================================\n",
      "Data:  MAR_data \t method: mean\n",
      "MSE =  0.0\n",
      "\n",
      "Data:  MAR_data \t method: median\n",
      "MSE =  0.0\n",
      "\n",
      "Data:  MAR_data \t method: most_frequent\n",
      "MSE =  0.0\n",
      "\n",
      "Data:  MAR_data \t method: multivariate_feature_imputation\n",
      "MSE =  0.0\n",
      "\n",
      "Data:  MAR_data \t method: knn\n",
      "MSE =  0.0\n",
      "\n",
      "=============================================\n",
      "Data:  MNAR_data \t method: mean\n",
      "MSE =  0.00542730207698105\n",
      "\n",
      "Data:  MNAR_data \t method: median\n",
      "MSE =  0.0037867525372867993\n",
      "\n",
      "Data:  MNAR_data \t method: most_frequent\n",
      "MSE =  0.0022568687248694197\n",
      "\n",
      "Data:  MNAR_data \t method: multivariate_feature_imputation\n",
      "MSE =  0.002222576298046997\n",
      "\n",
      "Data:  MNAR_data \t method: knn\n",
      "MSE =  0.00017895805941809065\n",
      "\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "for key in data_dict.keys(): \n",
    "    for method in ['mean', 'median', 'most_frequent', 'multivariate_feature_imputation', 'knn']: \n",
    "        print(\"Data: \", key, '\\t method:', method)\n",
    "        run(data_dict[key][0], data_dict[key][1], method)\n",
    "        print() \n",
    "    print(\"=============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33cc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
