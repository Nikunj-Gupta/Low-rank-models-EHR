{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SEQN  RIDAGEYR  RIAGENDR  RIDRETH1  RIDRETH3  DMDCITZN  DMDEDUC2  MIALANG  \\\n",
      "0  73557        69         1         4         4       1.0       3.0      1.0   \n",
      "1  73558        54         1         3         3       1.0       3.0      1.0   \n",
      "2  73559        72         1         3         3       1.0       4.0      1.0   \n",
      "3  73561        73         2         3         3       1.0       5.0      1.0   \n",
      "4  73562        56         1         1         1       1.0       4.0      1.0   \n",
      "\n",
      "   DMDHHSIZ  INDHHIN2  ...  PAQ635  PAQ650  PAQ665  PAD680  PAQ706  PAQ710  \\\n",
      "0         3       4.0  ...       2       2       2   600.0     NaN     2.0   \n",
      "1         4       7.0  ...       2       2       2   540.0     NaN     4.0   \n",
      "2         2      10.0  ...       2       2       1   300.0     NaN     4.0   \n",
      "3         2      15.0  ...       2       2       2   480.0     NaN     1.0   \n",
      "4         1       9.0  ...       2       2       2   360.0     NaN     5.0   \n",
      "\n",
      "   LBXTC  highLDL  highbp        bmi  \n",
      "0  167.0      NaN     0.0  26.683761  \n",
      "1  170.0      NaN     1.0  28.632450  \n",
      "2  126.0      0.0     1.0  28.929300  \n",
      "3  201.0      0.0     1.0  19.716567  \n",
      "4  226.0      NaN     1.0  41.690341  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "Index(['SEQN', 'RIDAGEYR', 'RIAGENDR', 'RIDRETH1', 'RIDRETH3', 'DMDCITZN',\n",
      "       'DMDEDUC2', 'MIALANG', 'DMDHHSIZ', 'INDHHIN2', 'INDFMIN2', 'INDFMPIR',\n",
      "       'BMXLEG', 'BMXARML', 'BMXARMC', 'BMXWAIST', 'BMDAVSAD', 'BPXPLS',\n",
      "       'BPXPULS', 'CDQ001', 'CDQ010', 'DIQ010', 'DIQ160', 'DIQ170', 'DIQ172',\n",
      "       'DIQ180', 'DIQ050', 'DIQ070', 'DBQ095Z', 'DBD100', 'DRQSPREP', 'DR1STY',\n",
      "       'DRQSDIET', 'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TSUGR', 'DR1TFIBE',\n",
      "       'DR1TTFAT', 'DR1TSFAT', 'DR1TMFAT', 'DR1TPFAT', 'DR1TCHOL', 'DR1TSODI',\n",
      "       'DR1TALCO', 'DR1_320Z', 'LBDHDD', 'HIQ011', 'PAQ635', 'PAQ650',\n",
      "       'PAQ665', 'PAD680', 'PAQ706', 'PAQ710', 'LBXTC', 'highLDL', 'highbp',\n",
      "       'bmi'],\n",
      "      dtype='object')\n",
      "(5769, 58)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/data_clean.csv', sep=',', encoding='latin-1')\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data imputation for 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"BPXPLS\", \"BMXARMC\", \"bmi\", \"highbp\" ]]\n",
    "# df[\"highbp\"].isnull().sum()\n",
    "# df[\"highbp\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframe to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.isnull()] = 0\n",
    "df.shape\n",
    "np_array = df.to_numpy(copy=True, na_value=np.nan)\n",
    "\n",
    "# for column in df.columns:\n",
    "#     df_null_inx.append(df[df[column].isnull()].index.tolist())\n",
    "\n",
    "# # df_null_inx\n",
    "\n",
    "# for column in df.columns:\n",
    "#     df[column].fillna((df[column].mean()), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our code, we will first delete values ourselves and compare output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22128 20725 20047 ...  2724  5226 14841]\n",
      "[[        nan 35.3        26.68376063  0.        ]\n",
      " [74.         34.7        28.6324502   1.        ]\n",
      " [68.         33.5        28.92930024  1.        ]\n",
      " ...\n",
      " [72.58734271 31.         26.79702004  0.36274702]\n",
      " [60.         29.9        24.46863363  0.        ]\n",
      " [80.                 nan 34.01503875  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "data1 = np_array[~np.isnan(np_array).any(axis=1), :] #delete rows with any missing values\n",
    "#print(np.where(np.isnan(data1)))\n",
    "\n",
    "#create nans at random\n",
    "missing_indices = np.random.choice(len(data1.flatten()), size = int(len(data1.flatten())/10)) \n",
    "#randomly select values from length ie flat array\n",
    "print(missing_indices)\n",
    "\n",
    "data1_test = data1\n",
    "data1_test.flat[missing_indices] = np.nan\n",
    "print(data1_test)\n",
    "\n",
    "## data1 is our ground truth, data1_test is test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get non-missing indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     3 ... 23072 23074 23075]\n",
      "20871\n",
      "2205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## FIX: delete this line when no longer working with data1_test\n",
    "np_array = data1_test\n",
    "\n",
    "\n",
    "# nonmissing_indices = np.flatnonzero(np_array > 0.1)\n",
    "# nonmissing_indices = np_array.flat[np.argwhere(np.isfinite(np_array))]\n",
    "# nonmissing_indices = np_array.flat[np.isfinite(np_array.flat)]\n",
    "# nonmissing_indices = np.flatnonzero(~ np.isnan(np_array))\n",
    "nonmissing_indices = np.argwhere(~ np.isnan(np_array.flatten())).reshape(-1)\n",
    "missing_indices = np.argwhere(np.isnan(np_array.flatten())).reshape(-1)\n",
    "# nonmissing_indices.reshape(-1)\n",
    "print(nonmissing_indices)\n",
    "print(len(nonmissing_indices))\n",
    "print(len(missing_indices))\n",
    "\n",
    "# u, s, v = np.linalg.svd(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill an array with available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_ini = np.zeros(np_array.shape)\n",
    "rating_matrix_ini.flat[nonmissing_indices] = np_array.flat[nonmissing_indices]\n",
    "\n",
    "\n",
    "# rating_matrix_ini\n",
    "# for column in np_array.shape[1]:\n",
    "#     np_array[:,column] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False,  True, False, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_matrix_ini[6,:]\n",
    "# for column in range(np_array.shape[1]):\n",
    "#     np_array[np.where(np_array[:,column] == np.nan),column] = np.mean(np_array[:,column])\n",
    "col_mean = np.nanmean(np_array, axis=0)\n",
    "inds = np.where(np.isnan(np_array))\n",
    "np_array[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array.shape\n",
    "np.isnan(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit low rank model for rank 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Error: 7.468829130259888\n",
      "Iteration 0True Error: 29.561980869486945\n",
      "Iteration 1 Error: 5.98527519969878\n",
      "Iteration 1True Error: 22.831784347284753\n",
      "Iteration 2 Error: 5.3372011567625615\n",
      "Iteration 2True Error: 18.31956413970668\n",
      "Iteration 3 Error: 4.96966001303373\n",
      "Iteration 3True Error: 15.247428706950522\n",
      "Iteration 4 Error: 4.754995805395935\n",
      "Iteration 4True Error: 13.176518639463726\n",
      "[[56.97595451 26.31591662 23.32246418  0.29052326]\n",
      " [73.68492259 34.03341454 30.16209175  0.37572313]\n",
      " [69.02660514 31.8818421  28.25526206  0.35197013]\n",
      " ...\n",
      " [70.87796769 32.73694498 29.01309643  0.36141032]\n",
      " [60.70329694 28.03749256 24.84820975  0.30952916]\n",
      " [80.48338849 37.1734736  32.94496707  0.41038885]]\n"
     ]
    }
   ],
   "source": [
    "def fit_low_rank_model(rank,rating_matrix_ini,train_ind,train_data,n_iter,convergence_thresh,verbose, data1, missing_indices):\n",
    "    \"\"\"Fit the low rank model. \n",
    "    Return the estimation of the low rank model - (n_movies * n_users) matrix\n",
    "\n",
    "    Keyword arguments:\n",
    "    rank -- the rank of low rank model\n",
    "    rating_matrix_ini -- imputed initialization\n",
    "    train_ind -- index of training data\n",
    "    train_data -- ratings of training set\n",
    "    n_iter -- the max number of iterations\n",
    "    convergence_thresh -- the threshold of convergence to 0\n",
    "    \"\"\"\n",
    "    previous_fitting_error = 100\n",
    "    # Initialization\n",
    "    low_rank_estimate = np.zeros(rating_matrix_ini.shape)\n",
    "    # fill input data\n",
    "    low_rank_estimate.flat[train_ind] = train_data\n",
    "    # get the indexes of missing data\n",
    "    missing_inds = np.where(low_rank_estimate.flat == 0)\n",
    "    # fill missing data with imputed values\n",
    "    low_rank_estimate.flat[missing_inds] = rating_matrix_ini.flat[missing_inds]\n",
    "\n",
    "    \n",
    "    for ind in range(n_iter):\n",
    "        # Updates\n",
    "        low_rank_estimate.flat[train_ind] = train_data\n",
    "        u, s, v = np.linalg.svd(low_rank_estimate)\n",
    "        s_matrix = s  * np.eye(len(s))\n",
    "        low_rank_estimate = np.matmul(np.matmul(u[:,0:rank], s_matrix[0:rank,0:rank]), v[0:rank,:])\n",
    "        # Compute error\n",
    "        fitting_error = np.sqrt(((train_data - low_rank_estimate.flat[train_ind])**2).mean())\n",
    "        #true fitting error, compared to true values\n",
    "        true_fitting_error = np.sqrt(((data1.flat[missing_indices] - low_rank_estimate.flat[missing_indices])**2).mean())\n",
    "        if verbose:\n",
    "            print(\"Iteration \" + str(ind) + \" Error: \" + str(fitting_error))\n",
    "            print(\"Iteration \" + str(ind) + \"True Error: \" + str(true_fitting_error))\n",
    "        \n",
    "        # Stopping criterion\n",
    "        if (fitting_error <= convergence_thresh):\n",
    "            print('converged, breaking')\n",
    "            break\n",
    "    return low_rank_estimate\n",
    "\n",
    "n_iter = 5\n",
    "convergence_thresh = 1e-4\n",
    "verbose = True\n",
    "rank = 1\n",
    "train_data = np_array.flat[nonmissing_indices] \n",
    "estimate =fit_low_rank_model(rank,rating_matrix_ini,nonmissing_indices,\n",
    "        train_data,n_iter,convergence_thresh,verbose, data1, missing_indices)\n",
    "print(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare data1_test post imputation to data1 (true value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924.5142065093784"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(data1 - estimate, ord = \"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924.5142065093784"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np_array - estimate, ord = \"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.176518639463726"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np_array.flat[missing_indices]\n",
    "np.sqrt(((test_data - estimate.flat[missing_indices])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8552ac0c6e576d0bdc3bd33ce8ce0e25ff1726c17fcf557906b98a29d09c59b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
